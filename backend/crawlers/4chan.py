import requests
import re
import json
from datetime import datetime, timedelta
from typing import List, Dict, Optional, Tuple
import asyncio
import logging
from urllib.parse import urlparse, quote
import time
from dataclasses import dataclass
import hashlib

# ğŸ”¥ ì–¸ì–´íŒ© ì‹œìŠ¤í…œ import ì¶”ê°€
from core.messages import create_localized_message

# ë¡œê¹… ì„¤ì •
logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(name)s - %(levelname)s - %(message)s"
)
logger = logging.getLogger(__name__)

# ================================
# ğŸ”¥ 4chan ì„¤ì • ë° ìƒìˆ˜
# ================================

# 4chan API ì„¤ì •
FOURCHAN_CONFIG = {
    'api_timeout': 15,
    'max_pages': 10,
    'rate_limit_delay': 1.0,
    'user_agent': '4chanCrawler/1.0 (Image Board Crawler)',
    'cache_ttl': 300,
    'max_threads_per_page': 15,
    'max_replies_per_thread': 5
}

# 4chan API ì—”ë“œí¬ì¸íŠ¸
FOURCHAN_API_ENDPOINTS = {
    'catalog': 'https://a.4cdn.org/{board}/catalog.json',
    'threads': 'https://a.4cdn.org/{board}/threads.json',
    'thread': 'https://a.4cdn.org/{board}/thread/{thread_id}.json',
    'boards': 'https://a.4cdn.org/boards.json'
}

# 4chan ì´ë¯¸ì§€/ì¸ë„¤ì¼ URL
FOURCHAN_IMAGE_URLS = {
    'thumbnail': 'https://i.4cdn.org/{board}/{tim}s.jpg',
    'image': 'https://i.4cdn.org/{board}/{tim}{ext}',
    'thread_url': 'https://boards.4chan.org/{board}/thread/{no}',
    'board_url': 'https://boards.4chan.org/{board}/'
}

# ì£¼ìš” 4chan ê²Œì‹œíŒ ì •ë³´
FOURCHAN_BOARDS = {
    # ê¸°ìˆ /í”„ë¡œê·¸ë˜ë°
    'g': {'name': 'Technology', 'description': 'ê¸°ìˆ  ê²Œì‹œíŒ', 'nsfw': False},
    'sci': {'name': 'Science & Math', 'description': 'ê³¼í•™/ìˆ˜í•™', 'nsfw': False},
    'diy': {'name': 'Do It Yourself', 'description': 'DIY í”„ë¡œì íŠ¸', 'nsfw': False},
    
    # ì·¨ë¯¸/ê´€ì‹¬ì‚¬
    'v': {'name': 'Video Games', 'description': 'ë¹„ë””ì˜¤ ê²Œì„', 'nsfw': False},
    'vg': {'name': 'Video Game Generals', 'description': 'ê²Œì„ ì¼ë°˜', 'nsfw': False},
    'a': {'name': 'Anime & Manga', 'description': 'ì• ë‹ˆë©”ì´ì…˜/ë§Œí™”', 'nsfw': False},
    'co': {'name': 'Comics & Cartoons', 'description': 'ë§Œí™”/ì¹´íˆ°', 'nsfw': False},
    'mu': {'name': 'Music', 'description': 'ìŒì•…', 'nsfw': False},
    'tv': {'name': 'Television & Film', 'description': 'TV/ì˜í™”', 'nsfw': False},
    'lit': {'name': 'Literature', 'description': 'ë¬¸í•™', 'nsfw': False},
    'his': {'name': 'History & Humanities', 'description': 'ì—­ì‚¬/ì¸ë¬¸í•™', 'nsfw': False},
    
    # ì°½ì‘/ì˜ˆìˆ 
    'ic': {'name': 'Artwork/Critique', 'description': 'ì˜ˆìˆ  ì‘í’ˆ/ë¹„í‰', 'nsfw': False},
    'wg': {'name': 'Wallpapers/General', 'description': 'ë°°ê²½í™”ë©´/ì¼ë°˜', 'nsfw': False},
    'w': {'name': 'Anime/Wallpapers', 'description': 'ì• ë‹ˆë©”ì´ì…˜ ë°°ê²½í™”ë©´', 'nsfw': False},
    
    # ë¼ì´í”„ìŠ¤íƒ€ì¼
    'fit': {'name': 'Fitness', 'description': 'í”¼íŠ¸ë‹ˆìŠ¤', 'nsfw': False},
    'ck': {'name': 'Food & Cooking', 'description': 'ìŒì‹/ìš”ë¦¬', 'nsfw': False},
    'fa': {'name': 'Fashion', 'description': 'íŒ¨ì…˜', 'nsfw': False},
    'sp': {'name': 'Sports', 'description': 'ìŠ¤í¬ì¸ ', 'nsfw': False},
    'out': {'name': 'Outdoors', 'description': 'ì•„ì›ƒë„ì–´', 'nsfw': False},
    
    # ê¸°íƒ€
    'b': {'name': 'Random', 'description': 'ëœë¤ (NSFW)', 'nsfw': True},
    'pol': {'name': 'Politically Incorrect', 'description': 'ì •ì¹˜ (ë…¼ë€ì˜ ì—¬ì§€)', 'nsfw': True},
    'r9k': {'name': 'ROBOT9001', 'description': 'ë¡œë´‡', 'nsfw': True},
    'biz': {'name': 'Business & Finance', 'description': 'ë¹„ì¦ˆë‹ˆìŠ¤/ê¸ˆìœµ', 'nsfw': False},
    'int': {'name': 'International', 'description': 'êµ­ì œ', 'nsfw': False},
    'jp': {'name': 'Otaku Culture', 'description': 'ì˜¤íƒ€ì¿  ë¬¸í™”', 'nsfw': False},
    'k': {'name': 'Weapons', 'description': 'ë¬´ê¸°', 'nsfw': False},
    'o': {'name': 'Auto', 'description': 'ìë™ì°¨', 'nsfw': False},
    'p': {'name': 'Photography', 'description': 'ì‚¬ì§„', 'nsfw': False},
    'toy': {'name': 'Toys', 'description': 'ì¥ë‚œê°', 'nsfw': False},
    'trv': {'name': 'Travel', 'description': 'ì—¬í–‰', 'nsfw': False},
    'x': {'name': 'Paranormal', 'description': 'ì´ˆìì—°í˜„ìƒ', 'nsfw': False}
}

# 4chan URL íŒ¨í„´ (lemmy.py ìŠ¤íƒ€ì¼)
FOURCHAN_URL_PATTERNS = [
    r'^(?:https?://)?(?:www\.)?boards\.4chan\.org/([a-z0-9]+)/?$',  # ê²Œì‹œíŒ
    r'^(?:https?://)?(?:www\.)?boards\.4chan\.org/([a-z0-9]+)/thread/(\d+)/?',  # ìŠ¤ë ˆë“œ
    r'^(?:https?://)?(?:www\.)?boards\.4chan\.org/([a-z0-9]+)/catalog$',  # ì¹´íƒˆë¡œê·¸
    r'^(?:https?://)?(?:www\.)?4chan\.org/([a-z0-9]+)/?$',  # 4chan.org
    r'^([a-z0-9]+)$'  # ê²Œì‹œíŒ ì´ë¦„ë§Œ
]

# ì»´íŒŒì¼ëœ ì •ê·œí‘œí˜„ì‹
_compiled_4chan_patterns = [re.compile(pattern, re.IGNORECASE) for pattern in FOURCHAN_URL_PATTERNS]

# ================================
# ğŸ”¥ 4chan ë°ì´í„° í´ë˜ìŠ¤
# ================================

@dataclass
class FourchanPost:
    """4chan ê²Œì‹œë¬¼ ì •ë³´"""
    no: int
    name: str = "Anonymous"
    sub: str = ""  # ì œëª©
    com: str = ""  # ëŒ“ê¸€ ë‚´ìš©
    filename: str = ""
    ext: str = ""
    tim: str = ""  # íƒ€ì„ìŠ¤íƒ¬í”„ (ì´ë¯¸ì§€ íŒŒì¼ëª…)
    time: int = 0
    replies: int = 0
    images: int = 0
    bumplimit: int = 0
    imagelimit: int = 0
    semantic_url: str = ""
    w: int = 0  # ì´ë¯¸ì§€ ë„ˆë¹„
    h: int = 0  # ì´ë¯¸ì§€ ë†’ì´
    tn_w: int = 0  # ì¸ë„¤ì¼ ë„ˆë¹„
    tn_h: int = 0  # ì¸ë„¤ì¼ ë†’ì´
    fsize: int = 0  # íŒŒì¼ í¬ê¸°
    md5: str = ""
    resto: int = 0  # ë‹µê¸€ ëŒ€ìƒ (0ì´ë©´ OP)
    sticky: int = 0
    closed: int = 0
    archived: int = 0
    
@dataclass 
class FourchanBoard:
    """4chan ê²Œì‹œíŒ ì •ë³´"""
    board: str
    title: str
    ws_board: int = 0
    per_page: int = 15
    pages: int = 10
    max_filesize: int = 0
    max_webm_filesize: int = 0
    max_comment_chars: int = 2000
    max_webm_duration: int = 0
    bump_limit: int = 300
    image_limit: int = 150
    cooldowns: dict = None
    meta_description: str = ""
    spoilers: int = 0
    custom_spoilers: int = 0
    is_archived: int = 0
    troll_flags: int = 0
    country_flags: int = 0
    user_ids: int = 0
    oekaki: int = 0
    sjis_tags: int = 0
    code_tags: int = 0
    math_tags: int = 0
    text_only: int = 0
    forced_anon: int = 0
    webm_audio: int = 0
    require_subject: int = 0
    min_image_width: int = 0
    min_image_height: int = 0

# ================================
# ğŸ”¥ 4chan URL íŒŒì„œ
# ================================

class FourchanURLParser:
    """4chan URL íŒŒì‹± ë° ì •ê·œí™” (lemmy.py ìŠ¤íƒ€ì¼)"""
    
    @staticmethod
    def parse_board_input(board_input: str) -> Tuple[str, str, str]:
        """
        4chan ì…ë ¥ì„ ë¶„ì„í•˜ì—¬ URL, ê²Œì‹œíŒëª…, ìŠ¤ë ˆë“œID ë°˜í™˜
        ë°˜í™˜: (url, board_name, thread_id)
        """
        board_input = board_input.strip()
        
        # 1. ì „ì²´ URLì¸ ê²½ìš°
        if board_input.startswith('http'):
            return FourchanURLParser._parse_full_url(board_input)
        
        # 2. ê²Œì‹œíŒëª…ë§Œ ìˆëŠ” ê²½ìš° (ì˜ˆ: "g", "v", "pol")
        if re.match(r'^[a-z0-9]+$', board_input, re.IGNORECASE):
            board_name = board_input.lower()
            if board_name in FOURCHAN_BOARDS:
                url = f"https://boards.4chan.org/{board_name}/"
                return url, board_name, ""
            else:
                # ì•Œë ¤ì§€ì§€ ì•Šì€ ê²Œì‹œíŒì´ì§€ë§Œ ì‹œë„
                url = f"https://boards.4chan.org/{board_name}/"
                return url, board_name, ""
        
        # 3. ê¸°íƒ€ í˜•íƒœë“¤ ì‹œë„
        for pattern in _compiled_4chan_patterns:
            match = pattern.match(board_input)
            if match:
                groups = match.groups()
                if len(groups) >= 1:
                    board_name = groups[0].lower()
                    thread_id = groups[1] if len(groups) > 1 else ""
                    
                    if thread_id:
                        url = f"https://boards.4chan.org/{board_name}/thread/{thread_id}"
                    else:
                        url = f"https://boards.4chan.org/{board_name}/"
                    
                    return url, board_name, thread_id
        
        # ê¸°ë³¸ê°’
        return board_input, "", ""
    
    @staticmethod
    def _parse_full_url(url: str) -> Tuple[str, str, str]:
        """ì „ì²´ URL íŒŒì‹±"""
        parsed = urlparse(url)
        path = parsed.path.strip('/')
        
        # /board/thread/id í˜•íƒœ
        thread_match = re.match(r'([a-z0-9]+)/thread/(\d+)', path)
        if thread_match:
            board_name, thread_id = thread_match.groups()
            return url, board_name.lower(), thread_id
        
        # /board í˜•íƒœ
        board_match = re.match(r'([a-z0-9]+)/?', path)
        if board_match:
            board_name = board_match.group(1)
            return url, board_name.lower(), ""
        
        return url, "", ""
    
    @staticmethod
    def is_4chan_url(url: str) -> bool:
        """4chan URLì¸ì§€ í™•ì¸"""
        if not url:
            return False
            
        # ë„ë©”ì¸ í™•ì¸
        if any(domain in url.lower() for domain in ['4chan.org', 'boards.4chan.org', '4channel.org']):
            return True
        
        # íŒ¨í„´ í™•ì¸
        for pattern in _compiled_4chan_patterns:
            if pattern.match(url):
                return True
        
        return False

# ================================
# ğŸ”¥ 4chan ì¡°ê±´ ê²€ì‚¬ê¸°
# ================================

class FourchanConditionChecker:
    """4chan ì „ìš© ì¡°ê±´ ê²€ì‚¬ê¸°"""
    
    def __init__(self, min_views: int = 0, min_likes: int = 0, min_comments: int = 0,
                 start_date: str = None, end_date: str = None, include_media: bool = True,
                 include_nsfw: bool = True):
        self.min_views = min_views  # 4chanì—ì„œëŠ” repliesë¡œ ì‚¬ìš©
        self.min_likes = min_likes  # 4chanì—ì„œëŠ” ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
        self.min_comments = min_comments  # replies
        self.start_dt = self._parse_date(start_date)
        self.end_dt = self._parse_date(end_date)
        self.include_media = include_media
        self.include_nsfw = include_nsfw
        
        if self.end_dt:
            self.end_dt = self.end_dt.replace(hour=23, minute=59, second=59)
    
    def _parse_date(self, date_str: Optional[str]) -> Optional[datetime]:
        if not date_str:
            return None
        try:
            return datetime.strptime(date_str, '%Y-%m-%d')
        except Exception:
            return None
    
    def check_conditions(self, post: Dict) -> Tuple[bool, str]:
        """ê²Œì‹œë¬¼ ì¡°ê±´ ê²€ì‚¬"""
        
        # ë¯¸ë””ì–´ í•„í„°
        if not self.include_media and post.get('íŒŒì¼ëª…'):
            return False, "ë¯¸ë””ì–´ í•„í„°ë§"
        
        # NSFW í•„í„°
        board = post.get('ê²Œì‹œíŒ', '')
        if not self.include_nsfw and FOURCHAN_BOARDS.get(board, {}).get('nsfw', False):
            return False, "NSFW í•„í„°ë§"
        
        # ìµœì†Œ ëŒ“ê¸€ìˆ˜ (replies)
        if post.get('ëŒ“ê¸€ìˆ˜', 0) < self.min_comments:
            return False, f"ìµœì†Œ ëŒ“ê¸€ìˆ˜ {self.min_comments}ê°œ ë¯¸ë§Œ"
        
        # ë‚ ì§œ ê²€ì‚¬
        if self.start_dt and self.end_dt:
            post_date = self._extract_post_date(post)
            if post_date:
                if not (self.start_dt <= post_date <= self.end_dt):
                    return False, "ë‚ ì§œ ë²”ìœ„ ë²—ì–´ë‚¨"
        
        return True, "í†µê³¼"
    
    def _extract_post_date(self, post: Dict) -> Optional[datetime]:
        date_str = post.get('ì‘ì„±ì¼', '')
        if not date_str:
            return None
        
        formats = ['%Y.%m.%d %H:%M', '%Y-%m-%d %H:%M', '%Y.%m.%d', '%Y-%m-%d']
        for fmt in formats:
            try:
                return datetime.strptime(date_str.strip(), fmt)
            except ValueError:
                continue
        return None

# ================================
# ğŸ”¥ 4chan API í´ë¼ì´ì–¸íŠ¸
# ================================

class FourchanAPIClient:
    """4chan API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self):
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': FOURCHAN_CONFIG['user_agent']
        })
        self.rate_limiter = {}
        self.cache = {}
    
    def _apply_rate_limit(self, board: str):
        """ê²Œì‹œíŒë³„ ë ˆì´íŠ¸ ë¦¬ë¯¸í„°"""
        now = time.time()
        if board in self.rate_limiter:
            last_request = self.rate_limiter[board]
            elapsed = now - last_request
            if elapsed < FOURCHAN_CONFIG['rate_limit_delay']:
                time.sleep(FOURCHAN_CONFIG['rate_limit_delay'] - elapsed)
        
        self.rate_limiter[board] = time.time()
    
    def get_boards_list(self) -> List[Dict]:
        """ëª¨ë“  ê²Œì‹œíŒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            url = FOURCHAN_API_ENDPOINTS['boards']
            response = self.session.get(url, timeout=FOURCHAN_CONFIG['api_timeout'])
            response.raise_for_status()
            
            data = response.json()
            return data.get('boards', [])
            
        except Exception as e:
            logger.error(f"ê²Œì‹œíŒ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []
    
    def get_catalog(self, board: str) -> List[Dict]:
        """ê²Œì‹œíŒ ì¹´íƒˆë¡œê·¸ ê°€ì ¸ì˜¤ê¸° (ëª¨ë“  ìŠ¤ë ˆë“œ ìš”ì•½)"""
        try:
            self._apply_rate_limit(board)
            
            # ìºì‹œ í™•ì¸
            cache_key = f"catalog_{board}"
            if cache_key in self.cache:
                cached_data, timestamp = self.cache[cache_key]
                if time.time() - timestamp < FOURCHAN_CONFIG['cache_ttl']:
                    return cached_data
            
            url = FOURCHAN_API_ENDPOINTS['catalog'].format(board=board)
            response = self.session.get(url, timeout=FOURCHAN_CONFIG['api_timeout'])
            response.raise_for_status()
            
            data = response.json()
            
            # ìºì‹œ ì €ì¥
            self.cache[cache_key] = (data, time.time())
            
            return data
            
        except Exception as e:
            logger.error(f"ì¹´íƒˆë¡œê·¸ ì¡°íšŒ ì‹¤íŒ¨ ({board}): {e}")
            return []
    
    def get_thread(self, board: str, thread_id: str) -> Dict:
        """íŠ¹ì • ìŠ¤ë ˆë“œ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
        try:
            self._apply_rate_limit(board)
            
            url = FOURCHAN_API_ENDPOINTS['thread'].format(board=board, thread_id=thread_id)
            response = self.session.get(url, timeout=FOURCHAN_CONFIG['api_timeout'])
            response.raise_for_status()
            
            return response.json()
            
        except Exception as e:
            logger.error(f"ìŠ¤ë ˆë“œ ì¡°íšŒ ì‹¤íŒ¨ ({board}/{thread_id}): {e}")
            return {}
    
    def get_threads_list(self, board: str) -> List[Dict]:
        """ê²Œì‹œíŒì˜ ëª¨ë“  ìŠ¤ë ˆë“œ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
        try:
            self._apply_rate_limit(board)
            
            url = FOURCHAN_API_ENDPOINTS['threads'].format(board=board)
            response = self.session.get(url, timeout=FOURCHAN_CONFIG['api_timeout'])
            response.raise_for_status()
            
            return response.json()
            
        except Exception as e:
            logger.error(f"ìŠ¤ë ˆë“œ ëª©ë¡ ì¡°íšŒ ì‹¤íŒ¨ ({board}): {e}")
            return []

# ================================
# ğŸ”¥ 4chan í¬ë¡¤ëŸ¬
# ================================

class FourchanCrawler:
    """4chan ì „ìš© í¬ë¡¤ëŸ¬"""
    
    def __init__(self):
        self.api_client = FourchanAPIClient()
        self.url_parser = FourchanURLParser()
    
    async def crawl_4chan_board(self, board_input: str, limit: int = 50, sort: str = "recent",
                               min_views: int = 0, min_likes: int = 0, min_comments: int = 0,
                               start_date: str = None, end_date: str = None, 
                               include_media: bool = True, include_nsfw: bool = True,
                               time_filter: str = None,
                               websocket=None, start_index: int = 1, end_index: int = 20, 
                               user_lang: str = "en") -> List[Dict]:
        """4chan ê²Œì‹œíŒ í¬ë¡¤ë§"""
        
        try:
            logger.info(f"4chan í¬ë¡¤ë§ ì‹œì‘: {board_input}")
            
            # URL íŒŒì‹±
            url, board_name, thread_id = self.url_parser.parse_board_input(board_input)
            
            if not board_name:
                raise Exception(f"ì˜¬ë°”ë¥´ì§€ ì•Šì€ 4chan ê²Œì‹œíŒ: {board_input}\nì˜ˆì‹œ: g, v, pol, https://boards.4chan.org/g/")
            
            # ê²Œì‹œíŒ ì •ë³´ í™•ì¸
            board_info = FOURCHAN_BOARDS.get(board_name, {
                'name': board_name.upper(),
                'description': f'/{board_name}/ ê²Œì‹œíŒ',
                'nsfw': False
            })
            
            if websocket:
                # ğŸ”¥ ì–¸ì–´íŒ© ì‚¬ìš©í•˜ì—¬ ë©”ì‹œì§€ ìƒì„±
                message = create_localized_message(
                    progress=20,
                    status_key="crawlingProgress.site_connecting",
                    lang=user_lang,
                    status_data={"site": "4chan"}
                )
                await websocket.send_json(message)
            
            # ì¡°ê±´ ê²€ì‚¬ê¸° ì„¤ì •
            condition_checker = FourchanConditionChecker(
                min_views, min_likes, min_comments, start_date, end_date, 
                include_media, include_nsfw
            )
            
            posts = []
            
            # íŠ¹ì • ìŠ¤ë ˆë“œ í¬ë¡¤ë§
            if thread_id:
                posts = await self._crawl_single_thread(board_name, thread_id, condition_checker, websocket, user_lang)
            else:
                # ê²Œì‹œíŒ ì „ì²´ í¬ë¡¤ë§
                posts = await self._crawl_board_catalog(board_name, limit, sort, condition_checker, websocket, user_lang)
            
            if not posts:
                # ğŸ”¥ ì–¸ì–´íŒ©ì„ ì‚¬ìš©í•œ ì—ëŸ¬ ë©”ì‹œì§€ëŠ” ì˜ˆì™¸ë¡œ ë˜ì ¸ì„œ ìƒìœ„ì—ì„œ ì²˜ë¦¬í•˜ë„ë¡ í•¨
                error_msg = f"""
4chan /{board_name}/ ê²Œì‹œíŒì—ì„œ ê²Œì‹œë¬¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

ê°€ëŠ¥í•œ ì›ì¸:
1. ê²Œì‹œíŒì— ê²Œì‹œë¬¼ì´ ì—†ìŒ
2. ì„¤ì •í•œ ì¡°ê±´ì´ ë„ˆë¬´ ê¹Œë‹¤ë¡œì›€
3. ê²Œì‹œíŒì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ

ì‹œë„í•´ë³¼ ìˆ˜ ìˆëŠ” ê²Œì‹œíŒ:
â€¢ /g/ - Technology
â€¢ /v/ - Video Games  
â€¢ /a/ - Anime & Manga
â€¢ /mu/ - Music
â€¢ /fit/ - Fitness
                """
                raise Exception(error_msg.strip())
            
            # ë²”ìœ„ ì ìš©
            if posts and len(posts) >= end_index:
                posts = posts[start_index-1:end_index]
                
                # ë²ˆí˜¸ ì¬ë¶€ì—¬
                for idx, post in enumerate(posts):
                    post['ë²ˆí˜¸'] = start_index + idx
            
            logger.info(f"4chan í¬ë¡¤ë§ ì™„ë£Œ: {len(posts)}ê°œ ê²Œì‹œë¬¼")
            return posts
            
        except Exception as e:
            logger.error(f"4chan í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            raise
    
    async def _crawl_board_catalog(self, board_name: str, limit: int, sort: str, 
                                  condition_checker: FourchanConditionChecker, websocket=None, user_lang: str = "en") -> List[Dict]:
        """ê²Œì‹œíŒ ì¹´íƒˆë¡œê·¸ í¬ë¡¤ë§"""
        
        if websocket:
            # ğŸ”¥ ì–¸ì–´íŒ© ì‚¬ìš©í•˜ì—¬ ì¹´íƒˆë¡œê·¸ ë¶„ì„ ë©”ì‹œì§€
            message = create_localized_message(
                progress=40,
                status_key="crawlingProgress.posts_collecting",
                lang=user_lang,
                status_data={"site": "4chan"}
            )
            await websocket.send_json(message)
        
        try:
            catalog_data = self.api_client.get_catalog(board_name)
            
            if not catalog_data:
                return []
            
            posts = []
            processed_count = 0
            
            # ì¹´íƒˆë¡œê·¸ì˜ ê° í˜ì´ì§€ ì²˜ë¦¬
            for page_idx, page in enumerate(catalog_data):
                if processed_count >= limit:
                    break
                
                threads = page.get('threads', [])
                
                for thread_idx, thread in enumerate(threads):
                    if processed_count >= limit:
                        break
                    
                    # ìŠ¤ë ˆë“œë¥¼ ê²Œì‹œë¬¼ë¡œ ë³€í™˜
                    post_data = self._convert_thread_to_post(thread, board_name, processed_count + 1)
                    
                    if post_data:
                        # ì¡°ê±´ ê²€ì‚¬
                        passes, reason = condition_checker.check_conditions(post_data)
                        if passes:
                            posts.append(post_data)
                            processed_count += 1
                            
                            if websocket and processed_count % 5 == 0:
                                # ğŸ”¥ ì–¸ì–´íŒ© ì‚¬ìš©í•˜ì—¬ ì§„í–‰ ìƒí™© ë©”ì‹œì§€
                                message = create_localized_message(
                                    progress=40 + int((processed_count / limit) * 40),
                                    status_key="crawlingProgress.page_collecting",
                                    lang=user_lang,
                                    status_data={"page": page_idx + 1}
                                )
                                await websocket.send_json(message)
            
            # ì •ë ¬ ì ìš©
            sorted_posts = self._apply_4chan_sorting(posts, sort)
            
            return sorted_posts[:limit]
            
        except Exception as e:
            logger.error(f"ì¹´íƒˆë¡œê·¸ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return []
    
    async def _crawl_single_thread(self, board_name: str, thread_id: str, 
                                  condition_checker: FourchanConditionChecker, websocket=None, user_lang: str = "en") -> List[Dict]:
        """ë‹¨ì¼ ìŠ¤ë ˆë“œ í¬ë¡¤ë§"""
        
        if websocket:
            message = create_localized_message(
                progress=40,
                status_key="crawlingProgress.content_parsing",
                lang=user_lang
            )
            await websocket.send_json(message)
        
        try:
            thread_data = self.api_client.get_thread(board_name, thread_id)
            
            if not thread_data or 'posts' not in thread_data:
                return []
            
            posts = []
            thread_posts = thread_data['posts']
            
            for idx, post in enumerate(thread_posts[:FOURCHAN_CONFIG['max_replies_per_thread'] + 1]):
                post_data = self._convert_post_to_dict(post, board_name, idx + 1, thread_id)
                
                if post_data:
                    # ì¡°ê±´ ê²€ì‚¬
                    passes, reason = condition_checker.check_conditions(post_data)
                    if passes:
                        posts.append(post_data)
            
            return posts
            
        except Exception as e:
            logger.error(f"ìŠ¤ë ˆë“œ í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")
            return []
    
    def _convert_thread_to_post(self, thread: Dict, board_name: str, post_number: int) -> Optional[Dict]:
        """ìŠ¤ë ˆë“œ ë°ì´í„°ë¥¼ ê²Œì‹œë¬¼ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
        try:
            # ê¸°ë³¸ ì •ë³´
            thread_no = thread.get('no', 0)
            subject = thread.get('sub', '')
            comment = thread.get('com', '')
            
            # íŒŒì¼ ì •ë³´
            filename = thread.get('filename', '')
            ext = thread.get('ext', '')
            tim = thread.get('tim', '')
            
            # í†µê³„ ì •ë³´
            replies = thread.get('replies', 0)
            images = thread.get('images', 0)
            
            # ë‚ ì§œ ì •ë³´
            timestamp = thread.get('time', 0)
            
            # ì´ë¯¸ì§€ ì •ë³´
            width = thread.get('w', 0)
            height = thread.get('h', 0)
            filesize = thread.get('fsize', 0)
            
            # ì œëª© ìƒì„± (subjectê°€ ì—†ìœ¼ë©´ ë‚ ì§œ ë˜ëŠ” íŒŒì¼ëª… ì‚¬ìš©)
            if subject:
                title = subject
            elif filename:
                title = f"{filename}{ext}"
            else:
                # ì—…ë¡œë“œ ë‚ ì§œë¥¼ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
                if timestamp:
                    date_obj = datetime.fromtimestamp(timestamp)
                    title = date_obj.strftime('%Y.%m.%d %H:%M')
                else:
                    title = f"#{thread_no}"
            
            # ğŸ”¥ ì´ë¯¸ì§€ URL ìƒì„± (ì›ë³¸)
            image_url = ""
            if tim and ext and board_name:
                image_url = FOURCHAN_IMAGE_URLS['image'].format(
                    board=board_name, tim=tim, ext=ext
                )
            
            # ğŸ”¥ ì¸ë„¤ì¼ URLì€ ì›ë³¸ ì´ë¯¸ì§€ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
            thumbnail_url = image_url
            
            # ìŠ¤ë ˆë“œ URL
            thread_url = FOURCHAN_IMAGE_URLS['thread_url'].format(
                board=board_name, no=thread_no
            )
            
            # HTML íƒœê·¸ ì œê±° (4chan ëŒ“ê¸€ì—ì„œ)
            clean_comment = self._clean_html_content(comment)
            
            return {
                "ë²ˆí˜¸": post_number,
                "ì›ì œëª©": title,
                "ë²ˆì—­ì œëª©": None,
                "ë§í¬": thread_url,
                "ì›ë¬¸URL": thread_url,
                "ì¸ë„¤ì¼ URL": thumbnail_url,
                "ì´ë¯¸ì§€ URL": image_url,
                "ë³¸ë¬¸": clean_comment[:300] + "..." if len(clean_comment) > 300 else clean_comment,
                "ì¡°íšŒìˆ˜": replies,  # 4chanì—ì„œëŠ” repliesë¥¼ ì¡°íšŒìˆ˜ë¡œ ì‚¬ìš©
                "ì¶”ì²œìˆ˜": 0,  # 4chanì—ëŠ” ì¶”ì²œ ì‹œìŠ¤í…œ ì—†ìŒ
                "ëŒ“ê¸€ìˆ˜": replies,
                "ì´ë¯¸ì§€ìˆ˜": images,
                "ì‘ì„±ì¼": self._format_4chan_date(timestamp),
                "ì‘ì„±ì": "Anonymous",
                "ê²Œì‹œíŒ": board_name,
                "ìŠ¤ë ˆë“œë²ˆí˜¸": thread_no,
                "íŒŒì¼ëª…": filename,
                "íŒŒì¼í™•ì¥ì": ext,
                "íŒŒì¼í¬ê¸°": filesize,
                "ì´ë¯¸ì§€í¬ê¸°": f"{width}x{height}" if width and height else "",
                "íƒ€ì„ìŠ¤íƒ¬í”„": tim,
                "nsfw": FOURCHAN_BOARDS.get(board_name, {}).get('nsfw', False),
                "í¬ë¡¤ë§ë°©ì‹": "4chan-Catalog-API",
                "í”Œë«í¼": "4chan"
            }
            
        except Exception as e:
            logger.debug(f"ìŠ¤ë ˆë“œ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return None
    
    def _convert_post_to_dict(self, post: Dict, board_name: str, post_number: int, thread_id: str) -> Optional[Dict]:
        """ê°œë³„ ê²Œì‹œë¬¼ ë°ì´í„°ë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        try:
            # ê¸°ë³¸ ì •ë³´
            post_no = post.get('no', 0)
            name = post.get('name', 'Anonymous')
            subject = post.get('sub', '')
            comment = post.get('com', '')
            
            # íŒŒì¼ ì •ë³´
            filename = post.get('filename', '')
            ext = post.get('ext', '')
            tim = post.get('tim', '')
            
            # ë‚ ì§œ ì •ë³´
            timestamp = post.get('time', 0)
            
            # ì´ë¯¸ì§€ ì •ë³´
            width = post.get('w', 0)
            height = post.get('h', 0)
            filesize = post.get('fsize', 0)
            
            # ì œëª© ìƒì„±
            if subject:
                title = subject
            elif filename:
                title = f"{filename}{ext}"
            elif post_number == 1:
                title = f"ìŠ¤ë ˆë“œ #{thread_id}"
            else:
                title = f"ë‹µê¸€ #{post_no}"
            
            # ğŸ”¥ ì´ë¯¸ì§€ URL ìƒì„± (ì›ë³¸)
            image_url = ""
            if tim and ext and board_name:
                image_url = FOURCHAN_IMAGE_URLS['image'].format(
                    board=board_name, tim=tim, ext=ext
                )
            
            # ğŸ”¥ ì¸ë„¤ì¼ URLì€ ì›ë³¸ ì´ë¯¸ì§€ì™€ ë™ì¼í•˜ê²Œ ì„¤ì •
            thumbnail_url = image_url
            
            # ê²Œì‹œë¬¼ URL
            post_url = f"https://boards.4chan.org/{board_name}/thread/{thread_id}#{post_no}"
            
            # HTML íƒœê·¸ ì œê±°
            clean_comment = self._clean_html_content(comment)
            
            return {
                "ë²ˆí˜¸": post_number,
                "ì›ì œëª©": title,
                "ë²ˆì—­ì œëª©": None,
                "ë§í¬": post_url,
                "ì›ë¬¸URL": post_url,
                "ì¸ë„¤ì¼ URL": thumbnail_url,
                "ì´ë¯¸ì§€ URL": image_url,
                "ë³¸ë¬¸": clean_comment[:300] + "..." if len(clean_comment) > 300 else clean_comment,
                "ì¡°íšŒìˆ˜": 0,  # ê°œë³„ ê²Œì‹œë¬¼ì—ëŠ” ì¡°íšŒìˆ˜ ì—†ìŒ
                "ì¶”ì²œìˆ˜": 0,
                "ëŒ“ê¸€ìˆ˜": 0,
                "ì‘ì„±ì¼": self._format_4chan_date(timestamp),
                "ì‘ì„±ì": name,
                "ê²Œì‹œíŒ": board_name,
                "ìŠ¤ë ˆë“œë²ˆí˜¸": thread_id,
                "ê²Œì‹œë¬¼ë²ˆí˜¸": post_no,
                "íŒŒì¼ëª…": filename,
                "íŒŒì¼í™•ì¥ì": ext,
                "íŒŒì¼í¬ê¸°": filesize,
                "ì´ë¯¸ì§€í¬ê¸°": f"{width}x{height}" if width and height else "",
                "íƒ€ì„ìŠ¤íƒ¬í”„": tim,
                "OPì—¬ë¶€": post_number == 1,
                "nsfw": FOURCHAN_BOARDS.get(board_name, {}).get('nsfw', False),
                "í¬ë¡¤ë§ë°©ì‹": "4chan-Thread-API",
                "í”Œë«í¼": "4chan"
            }
            
        except Exception as e:
            logger.debug(f"ê²Œì‹œë¬¼ ë³€í™˜ ì˜¤ë¥˜: {e}")
            return None
    
    def _clean_html_content(self, html_content: str) -> str:
        """4chan HTML íƒœê·¸ ì œê±° ë° ì •ë¦¬"""
        if not html_content:
            return ""
        
        # ê¸°ë³¸ HTML íƒœê·¸ ì œê±°
        import re
        
        # 4chan íŠ¹í™” ì •ë¦¬
        content = html_content
        
        # <br> íƒœê·¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ
        content = re.sub(r'<br\s*/?>', '\n', content)
        
        # ì¸ìš© ì²˜ë¦¬ (>>ë²ˆí˜¸)
        content = re.sub(r'<a[^>]*class="quotelink"[^>]*>&gt;&gt;(\d+)</a>', r'>>\1', content)
        
        # ì¼ë°˜ ë§í¬ ì²˜ë¦¬
        content = re.sub(r'<a[^>]*href="([^"]*)"[^>]*>([^<]*)</a>', r'\2 (\1)', content)
        
        # êµµì€ ê¸€ì”¨ ì²˜ë¦¬
        content = re.sub(r'<b>(.*?)</b>', r'**\1**', content)
        content = re.sub(r'<strong>(.*?)</strong>', r'**\1**', content)
        
        # ê¸°ìš¸ì„ ì²˜ë¦¬
        content = re.sub(r'<i>(.*?)</i>', r'*\1*', content)
        content = re.sub(r'<em>(.*?)</em>', r'*\1*', content)
        
        # ë‚˜ë¨¸ì§€ HTML íƒœê·¸ ì œê±°
        content = re.sub(r'<[^>]+>', '', content)
        
        # HTML ì—”í‹°í‹° ë””ì½”ë”©
        import html
        content = html.unescape(content)
        
        # ì—¬ëŸ¬ ì¤„ë°”ê¿ˆì„ í•˜ë‚˜ë¡œ
        content = re.sub(r'\n\s*\n', '\n', content)
        
        return content.strip()
    
    def _format_4chan_date(self, timestamp: int) -> str:
        """4chan íƒ€ì„ìŠ¤íƒ¬í”„ë¥¼ ë‚ ì§œ ë¬¸ìì—´ë¡œ ë³€í™˜"""
        if not timestamp:
            return datetime.now().strftime('%Y.%m.%d %H:%M')
        
        try:
            date_obj = datetime.fromtimestamp(timestamp)
            return date_obj.strftime('%Y.%m.%d %H:%M')
        except Exception:
            return datetime.now().strftime('%Y.%m.%d %H:%M')
    
    def _apply_4chan_sorting(self, posts: List[Dict], sort: str) -> List[Dict]:
        """4chan íŠ¹í™” ì •ë ¬"""
        if not posts:
            return posts
        
        try:
            sort_lower = sort.lower()
            
            if sort_lower in ["recent", "new", "latest"]:
                # ìµœì‹ ìˆœ (íƒ€ì„ìŠ¤íƒ¬í”„ ê¸°ì¤€)
                return sorted(posts, key=lambda x: x.get('íƒ€ì„ìŠ¤íƒ¬í”„', ''), reverse=True)
            
            elif sort_lower in ["popular", "hot", "active"]:
                # ì¸ê¸°ìˆœ (ë‹µê¸€ìˆ˜ ê¸°ì¤€)
                return sorted(posts, key=lambda x: x.get('ëŒ“ê¸€ìˆ˜', 0), reverse=True)
            
            elif sort_lower in ["images", "media"]:
                # ì´ë¯¸ì§€ê°€ ìˆëŠ” ê²ƒ ìš°ì„ 
                return sorted(posts, key=lambda x: (x.get('ì´ë¯¸ì§€ìˆ˜', 0), x.get('ëŒ“ê¸€ìˆ˜', 0)), reverse=True)
            
            elif sort_lower == "oldest":
                # ì˜¤ë˜ëœ ìˆœ
                return sorted(posts, key=lambda x: x.get('íƒ€ì„ìŠ¤íƒ¬í”„', ''), reverse=False)
            
            elif sort_lower == "replies":
                # ë‹µê¸€ ë§ì€ ìˆœ
                return sorted(posts, key=lambda x: x.get('ëŒ“ê¸€ìˆ˜', 0), reverse=True)
            
            else:
                # ê¸°ë³¸ê°’: ìµœì‹ ìˆœ
                return sorted(posts, key=lambda x: x.get('íƒ€ì„ìŠ¤íƒ¬í”„', ''), reverse=True)
            
        except Exception as e:
            logger.error(f"ì •ë ¬ ì˜¤ë¥˜: {e}")
            return posts

# ================================
# ğŸ”¥ ê²€ìƒ‰ ë° ìë™ì™„ì„± ê¸°ëŠ¥
# ================================

class FourchanBoardSearcher:
    """4chan ê²Œì‹œíŒ ê²€ìƒ‰ ë° ìë™ì™„ì„±"""
    
    @staticmethod
    def search_boards(keyword: str) -> List[Dict]:
        """í‚¤ì›Œë“œë¡œ ê²Œì‹œíŒ ê²€ìƒ‰"""
        keyword = keyword.lower().strip()
        matches = []
        
        for board_code, board_info in FOURCHAN_BOARDS.items():
            # ê²Œì‹œíŒ ì½”ë“œ ë§¤ì¹­
            if keyword in board_code:
                matches.append({
                    'code': board_code,
                    'name': board_info['name'],
                    'description': board_info['description'],
                    'url': f"https://boards.4chan.org/{board_code}/",
                    'nsfw': board_info['nsfw'],
                    'match_type': 'code'
                })
            
            # ê²Œì‹œíŒ ì´ë¦„ ë§¤ì¹­
            elif keyword in board_info['name'].lower():
                matches.append({
                    'code': board_code,
                    'name': board_info['name'],
                    'description': board_info['description'],
                    'url': f"https://boards.4chan.org/{board_code}/",
                    'nsfw': board_info['nsfw'],
                    'match_type': 'name'
                })
            
            # ì„¤ëª… ë§¤ì¹­
            elif keyword in board_info['description'].lower():
                matches.append({
                    'code': board_code,
                    'name': board_info['name'],
                    'description': board_info['description'],
                    'url': f"https://boards.4chan.org/{board_code}/",
                    'nsfw': board_info['nsfw'],
                    'match_type': 'description'
                })
        
        # ì •ë ¬: code ë§¤ì¹­ > name ë§¤ì¹­ > description ë§¤ì¹­
        priority = {'code': 0, 'name': 1, 'description': 2}
        matches.sort(key=lambda x: (priority[x['match_type']], x['code']))
        
        return matches[:15]  # ìµœëŒ€ 15ê°œ
    
    @staticmethod
    def get_popular_boards() -> List[Dict]:
        """ì¸ê¸° ê²Œì‹œíŒ ëª©ë¡"""
        popular_codes = ['g', 'v', 'a', 'mu', 'fit', 'ck', 'tv', 'pol', 'b', 'sci']
        
        popular_boards = []
        for code in popular_codes:
            if code in FOURCHAN_BOARDS:
                board_info = FOURCHAN_BOARDS[code]
                popular_boards.append({
                    'code': code,
                    'name': board_info['name'],
                    'description': board_info['description'],
                    'url': f"https://boards.4chan.org/{code}/",
                    'nsfw': board_info['nsfw']
                })
        
        return popular_boards
    
    @staticmethod
    def get_safe_boards() -> List[Dict]:
        """SFW(Safe for Work) ê²Œì‹œíŒë§Œ"""
        safe_boards = []
        
        for code, info in FOURCHAN_BOARDS.items():
            if not info.get('nsfw', False):
                safe_boards.append({
                    'code': code,
                    'name': info['name'],
                    'description': info['description'],
                    'url': f"https://boards.4chan.org/{code}/",
                    'nsfw': False
                })
        
        # ì¸ê¸°ë„ìˆœ ì •ë ¬ (ì„ì˜ì˜ ìˆœì„œ)
        priority_order = ['g', 'v', 'a', 'mu', 'sci', 'diy', 'fit', 'ck', 'tv', 'co', 'lit', 'his']
        
        def get_priority(board):
            try:
                return priority_order.index(board['code'])
            except ValueError:
                return 999
        
        safe_boards.sort(key=get_priority)
        return safe_boards

# ================================
# ğŸ”¥ ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜
# ================================

async def crawl_4chan_board(board_input: str, limit: int = 50, sort: str = "recent",
                              min_views: int = 0, min_likes: int = 0, min_comments: int = 0,
                              start_date: str = None, end_date: str = None,
                              include_media: bool = True, include_nsfw: bool = True,
                              time_filter: str = None,
                              websocket=None, start_index: int = 1, end_index: int = 20, 
                              user_lang: str = "en") -> List[Dict]:
    """4chan ê²Œì‹œíŒ í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜"""
    
    crawler = FourchanCrawler()
    
    try:
        logger.info(f"4chan í¬ë¡¤ë§ ì‹œì‘: {board_input} (ë²”ìœ„: {start_index}-{end_index})")
        
        # í¬ë¡¤ë§ ì‹¤í–‰
        posts = await crawler.crawl_4chan_board(
            board_input=board_input,
            limit=max(end_index + 10, 50),  # ì—¬ìœ ë¶„ í¬í•¨
            sort=sort,
            min_views=min_views,
            min_likes=min_likes,
            min_comments=min_comments,
            start_date=start_date,
            end_date=end_date,
            include_media=include_media,
            include_nsfw=include_nsfw,
            time_filter=time_filter,
            websocket=websocket,
            start_index=start_index,
            end_index=end_index,
            user_lang=user_lang
        )
        
        logger.info(f"4chan í¬ë¡¤ë§ ì™„ë£Œ: {len(posts)}ê°œ ê²Œì‹œë¬¼")
        return posts
        
    except Exception as e:
        logger.error(f"4chan í¬ë¡¤ë§ ë©”ì¸ í•¨ìˆ˜ ì˜¤ë¥˜: {e}")
        raise

# ================================
# ğŸ”¥ ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤
# ================================

def detect_4chan_url_and_extract_info(url: str) -> Dict:
    """4chan URL ê°ì§€ ë° ì •ë³´ ì¶”ì¶œ (BBC ìŠ¤íƒ€ì¼)"""
    parser = FourchanURLParser()
    
    if parser.is_4chan_url(url):
        parsed_url, board_name, thread_id = parser.parse_board_input(url)
        
        board_info = FOURCHAN_BOARDS.get(board_name, {})
        
        return {
            "is_4chan": True,
            "board_name": board_name,
            "thread_id": thread_id,
            "board_title": board_info.get('name', board_name.upper()),
            "board_description": board_info.get('description', f'/{board_name}/ ê²Œì‹œíŒ'),
            "nsfw": board_info.get('nsfw', False),
            "parsed_url": parsed_url,
            "input_type": "thread" if thread_id else "board"
        }
    
    return {"is_4chan": False}

def get_4chan_autocomplete_suggestions(keyword: str) -> List[str]:
    """4chan ìë™ì™„ì„± ì œì•ˆ"""
    searcher = FourchanBoardSearcher()
    matches = searcher.search_boards(keyword)
    
    suggestions = []
    for match in matches:
        suggestions.append(f"/{match['code']}/ - {match['name']}")
    
    return suggestions[:10]

def is_4chan_board_safe(board_name: str) -> bool:
    """ê²Œì‹œíŒì´ SFWì¸ì§€ í™•ì¸"""
    board_info = FOURCHAN_BOARDS.get(board_name.lower(), {})
    return not board_info.get('nsfw', False)

# ================================
# ğŸ”¥ ëª¨ë“ˆ ë©”íƒ€ë°ì´í„°
# ================================

# ëª¨ë“ˆ ì •ë³´ (ë™ì  íƒì§€ë¥¼ ìœ„í•œ ë©”íƒ€ë°ì´í„°)
DISPLAY_NAME = "4chan Crawler"
DESCRIPTION = "4chan ì´ë¯¸ì§€ë³´ë“œ í¬ë¡¤ëŸ¬"
VERSION = "1.0.0"
SUPPORTED_DOMAINS = ["4chan.org", "boards.4chan.org", "4channel.org"]
KEYWORDS = ["4chan", "imageboard", "anonymous"]

# ëª¨ë“ˆ ë¡œë“œ í™•ì¸
logger.info("ğŸ”¥ 4chan í¬ë¡¤ëŸ¬ v1.0 ë¡œë“œ ì™„ë£Œ")
logger.info(f"ğŸ“Š ì§€ì› ê²Œì‹œíŒ: {len(FOURCHAN_BOARDS)}ê°œ")
logger.info(f"ğŸ¯ API ì—”ë“œí¬ì¸íŠ¸: {len(FOURCHAN_API_ENDPOINTS)}ê°œ")
logger.info(f"âš™ï¸ ì„¤ì •: {FOURCHAN_CONFIG['api_timeout']}s timeout, {FOURCHAN_CONFIG['cache_ttl']}s cache")
logger.info(f"ğŸ” URL íŒ¨í„´: {len(FOURCHAN_URL_PATTERNS)}ê°œ ì •ê·œí‘œí˜„ì‹")
logger.info(f"ğŸ–¼ï¸ ì¸ë„¤ì¼ ì§€ì›: ìë™ ì¶”ì¶œ ë° í‘œì‹œ")