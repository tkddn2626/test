# blind.py - Blind í¬ë¡¤ë§ ë° í•„í„°ë§ ì™„ì „ êµ¬í˜„

import requests
from bs4 import BeautifulSoup
import json
import os
import re
import asyncio
from datetime import datetime, timedelta
from typing import Tuple, List, Dict, Optional

# ë©”ì‹œì§€ ì‹œìŠ¤í…œ ì„í¬íŠ¸
from core.messages import (
    create_progress_message, create_status_message, create_error_message,
    create_success_message, create_complete_message, create_localized_message,
    CrawlStep, SiteType, ErrorCode, SuccessType,
    quick_progress, quick_error, quick_complete
)

# JSON íŒŒì¼ ê²½ë¡œ
BLIND_JSON_PATH = os.path.join("id_data", "boards.json")

def load_blind_map() -> dict:
    """Blind í† í”½ ë§µí•‘ ë°ì´í„° ë¡œë“œ"""
    if not os.path.exists(BLIND_JSON_PATH):
        print(f"Error: {BLIND_JSON_PATH} not found")
        return {}

    try:
        with open(BLIND_JSON_PATH, "r", encoding="utf-8") as f:
            data = json.load(f)
            print(f"Loaded boards.json ({len(data)} entries)")
            return data
    except Exception as e:
        print(f"Error parsing boards.json: {e}")
        return {}

def resolve_blind_board_id(keyword: str) -> str:
    """í‚¤ì›Œë“œë¥¼ Blind ë³´ë“œ IDë¡œ ìë™ ë§¤í•‘"""
    keyword = keyword.strip().lower()
    
    if not os.path.exists(BLIND_JSON_PATH):
        raise Exception("Error: boards.json not found. Run the builder script first.")
    
    with open(BLIND_JSON_PATH, "r", encoding="utf-8") as f:
        board_map = json.load(f)
    
    if not board_map:
        raise Exception("Error: boards.json is empty. Run the builder script first.")
    
    # ì§ì ‘ ë§¤ì¹˜ ì‹œë„
    if keyword in board_map:
        return board_map[keyword]
    
    # ë¶€ë¶„ ë§¤ì¹˜ ì‹œë„
    matches = [(name, board_id) for name, board_id in board_map.items() 
               if keyword in name.lower()]
    
    if not matches:
        raise Exception(f"No matching Blind topic for '{keyword}'.")
    
    name, board_id = matches[0]
    print(f"ğŸ“‹ Found topic: {name} (ID: {board_id})")
    return board_id

def extract_post_metrics(item) -> Tuple[int, int]:
    """ê²Œì‹œë¬¼ì—ì„œ ì¡°íšŒìˆ˜ì™€ ì¢‹ì•„ìš”ìˆ˜ ì¶”ì¶œ (ê°•í™”ë²„ì „)"""
    views = 0
    likes = 0

    try:
        # ì¡°íšŒìˆ˜ ì¶”ì¶œ
        view_selectors = [
            '.view-count', '.views', '[class*="view"]',
            '.count', '[data-view]', '.meta .count',
            '.stats .view', '.post-stats .views'
        ]
        for selector in view_selectors:
            view_elements = item.select(selector)
            for element in view_elements:
                text = element.text.strip()
                numbers = re.findall(r'\d+', text)
                if numbers and ('ì¡°íšŒ' in text or 'view' in text.lower() or len(numbers) == 1):
                    views = int(numbers[0])
                    break
            if views > 0:
                break

        # ì¢‹ì•„ìš”/ì¶”ì²œìˆ˜ ì¶”ì¶œ
        like_selectors = [
            '.like-count', '.likes', '.recommend', '[class*="like"]',
            '[class*="thumb"]', '.vote', '[data-like]', '.reaction',
            '.post-stats .likes', '.upvote'
        ]
        for selector in like_selectors:
            like_elements = item.select(selector)
            for element in like_elements:
                text = element.text.strip()
                numbers = re.findall(r'\d+', text)
                if numbers and ('ì¢‹ì•„ìš”' in text or 'ì¶”ì²œ' in text or 'like' in text.lower() or 'ğŸ‘' in text):
                    likes = int(numbers[0])
                    break
            if likes > 0:
                break
                
    except Exception as e:
        print(f"Error extracting metrics: {e}")

    return views, likes

def extract_post_date(item) -> str:
    """ê²Œì‹œë¬¼ ì‘ì„±ì¼ ì¶”ì¶œ"""
    date_selectors = [
        '.date', '.time', '.posting-time', '.created-at',
        '[class*="date"]', '[class*="time"]', '.meta .date',
        '.post-meta .date', '.timestamp'
    ]
    
    for selector in date_selectors:
        element = item.select_one(selector)
        if element:
            return element.text.strip()
    
    return "ë‚ ì§œ ì •ë³´ ì—†ìŒ"

def _parse_blind_date(date_text: str) -> Optional[datetime]:
    """Blind ë‚ ì§œ íŒŒì‹± (ìƒëŒ€ì /ì ˆëŒ€ì  ë‚ ì§œ ëª¨ë‘ ì§€ì›)"""
    if not date_text:
        return None
    
    try:
        now = datetime.now()
        
        # ìƒëŒ€ì  ì‹œê°„ íŒŒì‹±
        if 'ë¶„ ì „' in date_text or 'ë¶„ì „' in date_text:
            minutes = int(re.findall(r'\d+', date_text)[0])
            return now - timedelta(minutes=minutes)
        elif 'ì‹œê°„ ì „' in date_text or 'ì‹œê°„ì „' in date_text:
            hours = int(re.findall(r'\d+', date_text)[0])
            return now - timedelta(hours=hours)
        elif 'ì¼ ì „' in date_text or 'ì¼ì „' in date_text:
            days = int(re.findall(r'\d+', date_text)[0])
            return now - timedelta(days=days)
        elif 'ì£¼ ì „' in date_text or 'ì£¼ì „' in date_text:
            weeks = int(re.findall(r'\d+', date_text)[0])
            return now - timedelta(weeks=weeks)
        elif 'ê°œì›” ì „' in date_text or 'ë‹¬ ì „' in date_text:
            months = int(re.findall(r'\d+', date_text)[0])
            return now - timedelta(days=months * 30)  # ê·¼ì‚¬ì¹˜
        
        # ì˜ì–´ ìƒëŒ€ì‹œê°„
        if 'minute' in date_text.lower():
            minutes = int(re.findall(r'\d+', date_text)[0])
            return now - timedelta(minutes=minutes)
        elif 'hour' in date_text.lower():
            hours = int(re.findall(r'\d+', date_text)[0])
            return now - timedelta(hours=hours)
        elif 'day' in date_text.lower():
            days = int(re.findall(r'\d+', date_text)[0])
            return now - timedelta(days=days)
        elif 'week' in date_text.lower():
            weeks = int(re.findall(r'\d+', date_text)[0])
            return now - timedelta(weeks=weeks)
        
        # ì ˆëŒ€ì  ë‚ ì§œ íŒŒì‹±
        date_patterns = [
            r'(\d{4})\.(\d{1,2})\.(\d{1,2})',  # YYYY.MM.DD
            r'(\d{1,2})\.(\d{1,2})',          # MM.DD (ì˜¬í•´)
            r'(\d{4})-(\d{1,2})-(\d{1,2})',   # YYYY-MM-DD
            r'(\d{1,2})-(\d{1,2})',           # MM-DD (ì˜¬í•´)
            r'(\d{4})/(\d{1,2})/(\d{1,2})',   # YYYY/MM/DD
            r'(\d{1,2})/(\d{1,2})'            # MM/DD (ì˜¬í•´)
        ]
        
        for pattern in date_patterns:
            match = re.search(pattern, date_text)
            if match:
                groups = match.groups()
                if len(groups) == 3:  # YYYY.MM.DD í˜•íƒœ
                    year, month, day = map(int, groups)
                elif len(groups) == 2:  # MM.DD í˜•íƒœ (ì˜¬í•´)
                    year = now.year
                    month, day = map(int, groups)
                else:
                    continue
                
                return datetime(year, month, day)
    
    except Exception as e:
        print(f"Date parsing error: {e}")
    
    return None

class BlindConditionChecker:
    """Blind ê²Œì‹œë¬¼ ì¡°ê±´ ì²´í¬ í´ë˜ìŠ¤"""
    
    def __init__(self, min_views: int = 0, min_likes: int = 0, min_comments: int = 0,
                 start_date: str = None, end_date: str = None):
        self.min_views = min_views
        self.min_likes = min_likes
        self.min_comments = min_comments
        
        # ë‚ ì§œ ë²”ìœ„ íŒŒì‹±
        self.start_dt = None
        self.end_dt = None
        if start_date and end_date:
            try:
                self.start_dt = datetime.strptime(start_date, '%Y-%m-%d')
                self.end_dt = datetime.strptime(end_date, '%Y-%m-%d')
                self.end_dt = self.end_dt.replace(hour=23, minute=59, second=59)
            except Exception as e:
                print(f"ë‚ ì§œ íŒŒì‹± ì˜¤ë¥˜: {e}")

    def check_post_conditions(self, post: Dict) -> Tuple[bool, str]:
        """ê²Œì‹œë¬¼ì´ ì¡°ê±´ì„ ë§Œì¡±í•˜ëŠ”ì§€ í™•ì¸"""
        try:
            # ì¡°íšŒìˆ˜ ì²´í¬
            if post.get('ì¡°íšŒìˆ˜', 0) < self.min_views:
                return False, f"ì¡°íšŒìˆ˜ ë¶€ì¡±: {post.get('ì¡°íšŒìˆ˜', 0)} < {self.min_views}"
            
            # ì¶”ì²œìˆ˜ ì²´í¬
            if post.get('ì¶”ì²œìˆ˜', 0) < self.min_likes:
                return False, f"ì¶”ì²œìˆ˜ ë¶€ì¡±: {post.get('ì¶”ì²œìˆ˜', 0)} < {self.min_likes}"
            
            # ëŒ“ê¸€ìˆ˜ ì²´í¬
            if post.get('ëŒ“ê¸€ìˆ˜', 0) < self.min_comments:
                return False, f"ëŒ“ê¸€ìˆ˜ ë¶€ì¡±: {post.get('ëŒ“ê¸€ìˆ˜', 0)} < {self.min_comments}"
            
            # ë‚ ì§œ ë²”ìœ„ ì²´í¬
            if self.start_dt and self.end_dt:
                post_date = _parse_blind_date(post.get('ì‘ì„±ì¼', ''))
                if not post_date:
                    return False, "ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨"
                
                if not (self.start_dt <= post_date <= self.end_dt):
                    return False, "ë‚ ì§œ ë²”ìœ„ ë²—ì–´ë‚¨"
            
            return True, "ì¡°ê±´ ë§Œì¡±"
        
        except Exception as e:
            return False, f"ì¡°ê±´ ì²´í¬ ì˜¤ë¥˜: {e}"

    def should_stop_crawling(self, consecutive_fails: int, has_date_filter: bool) -> Tuple[bool, str]:
        """í¬ë¡¤ë§ ì¤‘ë‹¨ ì—¬ë¶€ ê²°ì •"""
        fail_threshold = 10 if has_date_filter else 20
        if consecutive_fails >= fail_threshold:
            return True, "ì¡°ê±´ ë¶ˆë§Œì¡±ìœ¼ë¡œ ì¤‘ë‹¨"
        return False, "ê³„ì† ì§„í–‰"

def _extract_blind_post_data(item) -> Optional[Dict]:
    """ê°œë³„ Blind ê²Œì‹œë¬¼ ë°ì´í„° ì¶”ì¶œ"""
    try:
        # ì œëª© ë° ë§í¬ ì¶”ì¶œ
        title_selectors = [
            "h3 > a", ".title a", ".subject a", 
            ".post-title a", ".article-title a"
        ]
        title_element = None
        for selector in title_selectors:
            title_element = item.select_one(selector)
            if title_element:
                break
        
        # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸° ì¶”ì¶œ
        body_selectors = [
            "p.pre-txt > a", ".preview", ".excerpt", 
            ".post-preview", ".content-preview"
        ]
        body_element = None
        for selector in body_selectors:
            body_element = item.select_one(selector)
            if body_element:
                break
        
        if not title_element:
            return None
        
        title = title_element.text.strip()
        link = title_element.get("href", "")
        
        # ì ˆëŒ€ URLë¡œ ë³€í™˜
        if link.startswith('/'):
            link = f"https://www.teamblind.com{link}"
        elif not link.startswith('http'):
            link = f"https://www.teamblind.com/{link}"
        
        # ë©”íŠ¸ë¦­ ì¶”ì¶œ
        views, likes = extract_post_metrics(item)
        
        # ëŒ“ê¸€ìˆ˜ ì¶”ì¶œ
        comments = 0
        comment_selectors = [
            '.comment-count', '.comments', '[class*="comment"]', 
            '.reply', '.replies', '[class*="reply"]'
        ]
        for selector in comment_selectors:
            comment_elements = item.select(selector)
            for element in comment_elements:
                comment_text = element.text.strip()
                comment_numbers = re.findall(r'\d+', comment_text)
                if comment_numbers:
                    comments = int(comment_numbers[0])
                    break
            if comments > 0:
                break
        
        # ë‚ ì§œ ë° ì‘ì„±ì ì¶”ì¶œ
        date_str = extract_post_date(item)
        author = _extract_author(item)
        
        # ë³¸ë¬¸ ë¯¸ë¦¬ë³´ê¸°
        body_text = body_element.text.strip() if body_element else ""
        
        return {
            "ì›ì œëª©": title,
            "ë²ˆì—­ì œëª©": None,
            "ë§í¬": link,
            "ë³¸ë¬¸": body_text,
            "ì¸ë„¤ì¼ URL": None,
            "ì¡°íšŒìˆ˜": views,
            "ì¶”ì²œìˆ˜": likes,
            "ëŒ“ê¸€ìˆ˜": comments,
            "ì‘ì„±ì¼": date_str,
            "ì‘ì„±ì": author,
            "í¬ë¡¤ë§ë°©ì‹": "Blind-Enhanced"
        }
    
    except Exception as e:
        print(f"Error extracting post data: {e}")
        return None

def _extract_author(item) -> str:
    """ì‘ì„±ì ì •ë³´ ì¶”ì¶œ"""
    author_selectors = [
        '.author', '.writer', '[class*="author"]', 
        '[class*="writer"]', '.nickname', '.user'
    ]
    
    for selector in author_selectors:
        author_element = item.select_one(selector)
        if author_element:
            return author_element.text.strip()
    
    return "ìµëª…"

async def _crawl_blind_page(base_url: str, page: int, websocket=None) -> List[Dict]:
    """Blind ë‹¨ì¼ í˜ì´ì§€ í¬ë¡¤ë§"""
    page_url = f"{base_url}{'&' if '?' in base_url else '?'}page={page}"
    
    headers = {
        "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
    }
    
    try:
        response = requests.get(page_url, headers=headers, timeout=10)
        if response.status_code != 200:
            return []
        
        soup = BeautifulSoup(response.text, "html.parser")
        
        # ë‹¤ì–‘í•œ ê²Œì‹œë¬¼ ë¦¬ìŠ¤íŠ¸ ì…€ë ‰í„° ì‹œë„
        item_selectors = [
            "div.article-list-pre",  # ê¸°ë³¸ Blind ë¦¬ìŠ¤íŠ¸
            ".post-item", ".article-item", 
            ".topic-item", ".list-item"
        ]
        
        items = []
        for selector in item_selectors:
            items = soup.select(selector)
            if items:
                break
        
        posts = []
        for item in items:
            try:
                post_data = _extract_blind_post_data(item)
                if post_data:
                    posts.append(post_data)
            except Exception as e:
                print(f"Error extracting post: {e}")
                continue
        
        return posts
    
    except Exception as e:
        print(f"Error crawling page {page}: {e}")
        return []

async def _execute_intelligent_blind_crawling(
    board_input: str, condition_checker, required_limit: int, sort: str,
    start_index: int, end_index: int, websocket=None, enforce_date_limit=False
) -> List[Dict]:
    """ì§€ëŠ¥í˜• Blind í¬ë¡¤ë§ ì‹¤í–‰"""
    
    board_id = resolve_blind_board_id(board_input)
    
    # URL êµ¬ì„±
    base_url = f"https://www.teamblind.com/kr/topics/{board_id}"
    
    # ì •ë ¬ íŒŒë¼ë¯¸í„° ì¶”ê°€
    sort_params = get_blind_sort_params(sort)
    if sort_params:
        base_url += f"?{sort_params}"
        
        if websocket:
            await websocket.send_json(
                create_progress_message(
                    progress=15,
                    step=CrawlStep.CONNECTING,
                    site=SiteType.BLIND,
                    board=board_input,
                    details={"sort_applied": sort}
                )
            )

    all_posts = []
    matched_posts = []
    consecutive_fails = 0
    page = 1
    max_pages = 200 if enforce_date_limit else min(20, (end_index // 20) + 3)
    
    if websocket:
        await websocket.send_json(
            create_progress_message(
                progress=25,
                step=CrawlStep.COLLECTING,
                site=SiteType.BLIND,
                board=board_input,
                details={"max_pages": max_pages}
            )
        )
    
    while page <= max_pages:
        try:
            if websocket:
                progress = min(25 + (page / max_pages) * 50, 75)
                await websocket.send_json(
                    create_progress_message(
                        progress=int(progress),
                        step=CrawlStep.COLLECTING,
                        site=SiteType.BLIND,
                        board=board_input,
                        details={
                            "current_page": page,
                            "matched_posts": len(matched_posts),
                            "target_range": f"{start_index}-{end_index}"
                        }
                    )
                )
            
            page_posts = await _crawl_blind_page(base_url, page, websocket)
            
            if not page_posts:
                consecutive_fails += 1
                if consecutive_fails >= 3:
                    break
                page += 1
                continue
            
            consecutive_fails = 0
            
            for post in page_posts:
                all_posts.append(post)
                
                # ì¡°ê±´ ì²´í¬
                is_valid, reason = condition_checker.check_post_conditions(post)
                if is_valid:
                    matched_posts.append(post)
                    
                    # ëª©í‘œ ê°œìˆ˜ ë‹¬ì„±ì‹œ ì¤‘ë‹¨
                    if len(matched_posts) >= (end_index - start_index + 1):
                        break
            
            # ì¤‘ë‹¨ ì¡°ê±´ ì²´í¬
            should_stop, stop_reason = condition_checker.should_stop_crawling(
                consecutive_fails, bool(condition_checker.start_dt and condition_checker.end_dt)
            )
            if should_stop:
                break
            
            # ëª©í‘œ ê°œìˆ˜ ë‹¬ì„±ì‹œ ì¤‘ë‹¨
            if len(matched_posts) >= (end_index - start_index + 1):
                break
            
            page += 1
            
        except Exception as e:
            print(f"Error on page {page}: {e}")
            page += 1
            if consecutive_fails > 5:
                break
    
    # ìµœì¢… ê²°ê³¼ ìŠ¬ë¼ì´ì‹±
    final_posts = matched_posts[start_index-1:end_index] if start_index <= len(matched_posts) else matched_posts
    
    # ë²ˆí˜¸ ë¶€ì—¬
    for idx, post in enumerate(final_posts):
        post['ë²ˆí˜¸'] = start_index + idx
    
    return final_posts

def get_blind_sort_params(sort_method: str) -> str:
    """Blind ì •ë ¬ íŒŒë¼ë¯¸í„° ìƒì„±"""
    blind_sort_map = {
        "popular": "sort=popular&order=desc",
        "recommend": "sort=recommend&order=desc",
        "comments": "sort=reply&order=desc",
        "recent": "sort=recent&order=desc",
        "hot": "sort=hot&order=desc",
    }
    
    return blind_sort_map.get(sort_method, "")

def sort_posts(posts, sort_method):
    """ê²Œì‹œë¬¼ ì •ë ¬ í•¨ìˆ˜"""
    if not posts:
        return posts
    
    try:
        if sort_method == "popular":
            # ì¡°íšŒìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            return sorted(posts, key=lambda x: x.get('ì¡°íšŒìˆ˜', 0), reverse=True)
        elif sort_method == "recommend":
            # ì¶”ì²œìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            return sorted(posts, key=lambda x: x.get('ì¶”ì²œìˆ˜', 0), reverse=True)
        elif sort_method == "comments":
            # ëŒ“ê¸€ìˆ˜ ê¸°ì¤€ ë‚´ë¦¼ì°¨ìˆœ ì •ë ¬
            return sorted(posts, key=lambda x: x.get('ëŒ“ê¸€ìˆ˜', 0), reverse=True)
        elif sort_method == "recent":
            # ìµœì‹ ìˆœ ì •ë ¬ (ê¸°ë³¸ ìˆœì„œ ìœ ì§€)
            return posts
        elif sort_method == "hot":
            # ì¸ê¸°ìˆœ (ì¡°íšŒìˆ˜ì™€ ì¶”ì²œìˆ˜ ì¡°í•©)
            return sorted(posts, key=lambda x: x.get('ì¡°íšŒìˆ˜', 0) + x.get('ì¶”ì²œìˆ˜', 0) * 2, reverse=True)
        else:
            return posts
    except Exception as e:
        print(f"ì •ë ¬ ì˜¤ë¥˜: {e}")
        return posts

# ==================== ë©”ì¸ í¬ë¡¤ë§ í•¨ìˆ˜ ====================

async def crawl_blind_board(
    board_input: str, limit: int = 50, sort: str = "recent",
    min_views: int = 0, min_likes: int = 0, min_comments: int = 0,
    time_filter: str = "all", start_date: str = None, end_date: str = None,
    websocket=None, enforce_date_limit=False, start_index: int = 1, end_index: int = 20
) -> List[Dict]:
    """ê°•í™”ëœ ì¡°ê±´ ê¸°ë°˜ ì§€ëŠ¥í˜• Blind í¬ë¡¤ë§"""
    
    try:
        if websocket:
            await websocket.send_json(
                create_progress_message(
                    progress=5,
                    step=CrawlStep.INITIALIZING,
                    site=SiteType.BLIND,
                    board=board_input,
                    details={
                        "sort": sort,
                        "range": f"{start_index}-{end_index}",
                        "filters": {
                            "min_views": min_views,
                            "min_likes": min_likes,
                            "min_comments": min_comments
                        }
                    }
                )
            )
        
        # ì¡°ê±´ ì²´ì»¤ ì´ˆê¸°í™”
        condition_checker = BlindConditionChecker(
            min_views=min_views,
            min_likes=min_likes,
            min_comments=min_comments,
            start_date=start_date,
            end_date=end_date
        )
        
        # í•„í„° ì ìš© ì—¬ë¶€ í™•ì¸
        has_filters = (min_views > 0 or min_likes > 0 or min_comments > 0 or 
                      (start_date and end_date))
        
        if has_filters:
            required_limit = min(end_index * 5, 500)
            enforce_date_limit = True
        else:
            required_limit = end_index + 10
            enforce_date_limit = False
        
        if websocket:
            await websocket.send_json(
                create_progress_message(
                    progress=10,
                    step=CrawlStep.DETECTING_SITE,
                    site=SiteType.BLIND,
                    board=board_input,
                    details={"filters_applied": has_filters}
                )
            )
        
        # ì§€ëŠ¥í˜• í¬ë¡¤ë§ ì‹¤í–‰
        final_posts = await _execute_intelligent_blind_crawling(
            board_input, condition_checker, required_limit, sort,
            start_index, end_index, websocket, enforce_date_limit
        )
        
        if websocket:
            await websocket.send_json(
                create_complete_message(
                    total_count=len(final_posts),
                    site=SiteType.BLIND,
                    board=board_input,
                    start_rank=start_index,
                    end_rank=start_index + len(final_posts) - 1 if final_posts else start_index
                )
            )
        
        print(f"Blind í¬ë¡¤ë§ ì™„ë£Œ: {len(final_posts)}ê°œ ê²Œì‹œë¬¼ ({start_index}-{start_index+len(final_posts)-1}ìœ„)")
        return final_posts
    
    except Exception as e:
        error_msg = f"Blind í¬ë¡¤ë§ ì˜¤ë¥˜: {str(e)}"
        print(error_msg)
        
        if websocket:
            await websocket.send_json(
                create_error_message(
                    error_code=ErrorCode.CRAWLING_ERROR,
                    error_detail=error_msg,
                    site=SiteType.BLIND
                )
            )
        
        return []

# ==================== ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ====================

def test_blind_sort_urls(board_input: str) -> dict:
    """ë‹¤ì–‘í•œ ì •ë ¬ URL í…ŒìŠ¤íŠ¸"""
    board_id = resolve_blind_board_id(board_input)
    base_url = f"https://www.teamblind.com/kr/topics/{board_id}"
    
    test_urls = {
        "default": base_url,
        "popular1": f"{base_url}?sort=popular&order=desc",
        "popular2": f"{base_url}?s=popular&o=desc",
        "recommend1": f"{base_url}?sort=recommend&order=desc",
        "recommend2": f"{base_url}?s=recommend&o=desc",
        "comments1": f"{base_url}?sort=reply&order=desc",
        "comments2": f"{base_url}?s=reply&o=desc",
        "recent1": f"{base_url}?sort=recent&order=desc",
        "recent2": f"{base_url}?s=latest&o=desc",
        "hot1": f"{base_url}?sort=hot&order=desc",
        "hot2": f"{base_url}?s=hot&o=desc"
    }
    
    return test_urls

def list_available_topics() -> None:
    """ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë“  Blind í† í”½ ì¶œë ¥"""
    board_map = load_blind_map()
    
    if not board_map:
        print("âŒ ë¡œë“œëœ Blind í† í”½ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ“‹ ì´ {len(board_map)}ê°œì˜ Blind í† í”½:")
    for i, (name, board_id) in enumerate(sorted(board_map.items()), 1):
        print(f"{i:3d}. {name} (ID: {board_id})")

def search_topics(keyword: str) -> None:
    """í‚¤ì›Œë“œë¡œ Blind í† í”½ ê²€ìƒ‰"""
    keyword = keyword.strip().lower()
    board_map = load_blind_map()
    
    if not board_map:
        print("âŒ ë¡œë“œëœ Blind í† í”½ì´ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    matches = [(name, board_id) for name, board_id in board_map.items() 
               if keyword in name.lower()]
    
    if not matches:
        print(f"âŒ '{keyword}'ì™€ ì¼ì¹˜í•˜ëŠ” í† í”½ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return
    
    print(f"\nğŸ” '{keyword}' ê²€ìƒ‰ ê²°ê³¼ ({len(matches)}ê°œ):")
    for i, (name, board_id) in enumerate(matches, 1):
        print(f"{i:3d}. {name} (ID: {board_id})")

def filter_by_time_period(posts, time_filter):
    """ì‹œê°„ ê¸°ê°„ìœ¼ë¡œ ê²Œì‹œë¬¼ í•„í„°ë§"""
    if time_filter == "all":
        return posts
    
    now = datetime.now()
    
    if time_filter == "day":
        cutoff = now - timedelta(days=1)
    elif time_filter == "week":
        cutoff = now - timedelta(weeks=1)
    elif time_filter == "month":
        cutoff = now - timedelta(days=30)
    elif time_filter == "year":
        cutoff = now - timedelta(days=365)
    else:
        return posts
    
    filtered_posts = []
    for post in posts:
        post_date = _parse_blind_date(post.get('ì‘ì„±ì¼', ''))
        if post_date and post_date >= cutoff:
            filtered_posts.append(post)
    
    print(f"Time filtering ({time_filter}): {len(filtered_posts)}/{len(posts)} posts")
    return filtered_posts